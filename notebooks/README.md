# ML Portfolio - Jupyter Notebooks

This directory contains comprehensive Jupyter notebooks for all 12 machine learning projects. Each notebook includes complete implementations with dataset loading, model training, evaluation, and inference demonstrations.

## ğŸ“š Available Notebooks

### Computer Vision
1. **[01_image_classification.ipynb](01_image_classification.ipynb)** - CIFAR-10 Image Classification
   - Dataset: CIFAR-10 (60,000 32x32 color images)
   - Model: SimpleCNN with BatchNorm and Dropout
   - Metrics: Accuracy, Precision, Recall, F1, Confusion Matrix
   - Status: âœ… Complete with training pipeline

2. **[02_object_detection.ipynb](02_object_detection.ipynb)** - COCO Object Detection
   - Dataset: COCO 2017
   - Model: Faster R-CNN / YOLO
   - Metrics: mAP, IoU
   - Status: ğŸ—ï¸ Template ready

3. **[03_instance_segmentation.ipynb](03_instance_segmentation.ipynb)** - COCO Instance Segmentation
   - Dataset: COCO 2017
   - Model: Mask R-CNN
   - Metrics: mAP, Mask IoU
   - Status: ğŸ—ï¸ Template ready

### Natural Language Processing
4. **[04_text_classification.ipynb](04_text_classification.ipynb)** - IMDb Sentiment Analysis
   - Dataset: IMDb Movie Reviews (50,000 reviews)
   - Model: BERT
   - Metrics: Accuracy, Precision, Recall, F1
   - Status: ğŸ—ï¸ Template ready

5. **[05_text_generation.ipynb](05_text_generation.ipynb)** - Text Generation with GPT-2
   - Dataset: Custom text corpus
   - Model: GPT-2
   - Metrics: Perplexity, BLEU
   - Status: ğŸ—ï¸ Template ready

6. **[06_machine_translation.ipynb](06_machine_translation.ipynb)** - English-German Translation
   - Dataset: WMT14
   - Model: Transformer
   - Metrics: BLEU, METEOR
   - Status: ğŸ—ï¸ Template ready

### Audio Processing
7. **[07_speech_emotion_recognition.ipynb](07_speech_emotion_recognition.ipynb)** - Emotion Recognition
   - Dataset: RAVDESS
   - Model: Wav2Vec2
   - Metrics: Accuracy, Confusion Matrix
   - Status: ğŸ—ï¸ Template ready

8. **[08_automatic_speech_recognition.ipynb](08_automatic_speech_recognition.ipynb)** - Speech-to-Text
   - Dataset: LibriSpeech
   - Model: Wav2Vec2 / Whisper
   - Metrics: WER, CER
   - Status: ğŸ—ï¸ Template ready

### Recommender Systems & Time Series
9. **[09_recommender_system.ipynb](09_recommender_system.ipynb)** - Movie Recommendations
   - Dataset: MovieLens-100K
   - Model: Neural Collaborative Filtering
   - Metrics: RMSE, Precision@K, NDCG@K
   - Status: ğŸ—ï¸ Template ready

10. **[10_time_series_forecasting.ipynb](10_time_series_forecasting.ipynb)** - Time Series Prediction
    - Dataset: Synthetic/Custom Time Series
    - Model: LSTM/Transformer
    - Metrics: MAE, RMSE, MAPE
    - Status: ğŸ—ï¸ Template ready

11. **[11_anomaly_detection.ipynb](11_anomaly_detection.ipynb)** - Fraud Detection
    - Dataset: Credit Card Fraud
    - Model: Autoencoder
    - Metrics: Precision, Recall, F1, ROC-AUC
    - Status: ğŸ—ï¸ Template ready

12. **[12_multimodal_fusion.ipynb](12_multimodal_fusion.ipynb)** - Multimodal Learning
    - Dataset: Custom Multimodal
    - Model: Multi-Input Network
    - Metrics: Task-specific metrics
    - Status: ğŸ—ï¸ Template ready

## ğŸš€ Getting Started

### Prerequisites

```bash
# Activate virtual environment
cd /path/to/MachineLearningPorjects
source aivenv/bin/activate

# Install required packages
pip install -r requirements.txt
```

### Download Datasets

```bash
# Run the dataset download script
python scripts/download_datasets.py
```

This will:
- âœ… Automatically download: CIFAR-10, IMDb, MovieLens-100K
- ğŸ“‹ Provide instructions for: COCO, RAVDESS, LibriSpeech, Credit Card Fraud
- ğŸ”„ Note datasets that auto-download during training

### Running Notebooks

1. **Start Jupyter Lab/Notebook:**
   ```bash
   jupyter lab
   # or
   jupyter notebook
   ```

2. **Navigate to `notebooks/` directory**

3. **Open any notebook and run cells sequentially**

Each notebook is self-contained and includes:
- âœ… Automatic CUDA/CPU detection
- âœ… Dataset loading and exploration
- âœ… Model architecture definition
- âœ… Complete training pipeline
- âœ… Comprehensive evaluation metrics
- âœ… Inference demonstrations
- âœ… Results saving (models + metrics)

## ğŸ“Š Notebook Structure

Each notebook follows a consistent structure:

```
1. Setup and Imports
   - Package installation
   - Library imports
   - Plotting configuration

2. Device Configuration (CUDA/CPU)
   - Automatic GPU/CPU detection
   - Device information display
   - Random seed setting

3. Data Loading and Exploration
   - Dataset downloading
   - Exploratory Data Analysis
   - Visualizations

4. Data Preprocessing
   - Transformations and augmentations
   - Train/val/test splits
   - DataLoader creation

5. Model Architecture
   - Model definition
   - Parameter counting
   - Architecture summary

6. Training Loop
   - Training configuration
   - Training and validation functions
   - Progress tracking with tqdm
   - Best model checkpointing

7. Evaluation and Metrics
   - Model loading
   - Predictions generation
   - Comprehensive metrics calculation
   - Confusion matrices and visualizations

8. Inference Demo
   - Sample predictions
   - Visualization of results
   - Error analysis

9. Save Results
   - Metrics export to JSON
   - Model saving
   - Visualization saving
```

## ğŸ’¾ Output Directories

Each notebook saves outputs to its respective project directory:

```
XX_Project_Name/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.pt          # Best trained model
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ metrics.json           # Evaluation metrics
â”‚   â”œâ”€â”€ training_history.png   # Loss/accuracy plots
â”‚   â”œâ”€â”€ confusion_matrix.png   # Confusion matrix
â”‚   â””â”€â”€ predictions.png        # Sample predictions
â””â”€â”€ checkpoints/               # Training checkpoints
```

## ğŸ”§ Device Support

All notebooks support both CUDA and CPU:

```python
# Automatic device selection
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# All models and data are automatically moved to the correct device
model = model.to(device)
inputs, labels = inputs.to(device), labels.to(device)
```

**GPU Recommendations:**
- Image/Video tasks: 8GB+ VRAM
- NLP (BERT-based): 12GB+ VRAM
- Audio processing: 8GB+ VRAM
- CPU works but will be slower

## ğŸ“ˆ Expected Training Times

Approximate training times on different hardware:

| Notebook | CPU (8 cores) | GPU (RTX 3080) |
|----------|---------------|----------------|
| Image Classification | 2-3 hours | 15-20 min |
| Object Detection | 8-10 hours | 1-2 hours |
| Text Classification (BERT) | 4-6 hours | 20-30 min |
| Speech Recognition | 6-8 hours | 1-2 hours |
| Recommender System | 30-60 min | 10-15 min |

## ğŸ› Troubleshooting

### Out of Memory (OOM) Errors
```python
# Reduce batch size in the notebook
batch_size = 16  # or 8, or even 4
```

### CUDA Out of Memory
```python
# Clear GPU cache
torch.cuda.empty_cache()

# Use gradient accumulation instead of larger batches
```

### Slow Training
```python
# Increase num_workers for data loading
num_workers = 4  # or 8, depending on CPU cores

# Enable pin_memory for faster data transfer to GPU
pin_memory = True
```

### Package Installation Issues
```bash
# Reinstall specific packages
pip install torch torchvision --upgrade

# For Detectron2 (Object Detection/Segmentation)
python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'
```

## ğŸ“ Customization

### Modify Hyperparameters

Each notebook has a configuration section:

```python
# Training configuration
num_epochs = 50
batch_size = 128
learning_rate = 0.001

# Modify as needed
num_epochs = 100  # Train longer
batch_size = 64   # Reduce for less memory
learning_rate = 0.0001  # Lower for fine-tuning
```

### Change Model Architecture

```python
# Most notebooks support multiple models
model = SimpleCNN(num_classes=10)  # Simple model
# or
model = models.resnet18(pretrained=True)  # Pre-trained ResNet
# or
model = models.efficientnet_b0(pretrained=True)  # EfficientNet
```

### Add Experiment Tracking

```python
# Add W&B tracking
import wandb

wandb.init(project="ml-portfolio", name="experiment-1")

# Log metrics during training
wandb.log({"train_loss": train_loss, "val_acc": val_acc})
```

## ğŸ”— Integration with Web App

These notebooks serve as the foundation for the web application (Phase 2):
- Trained models will be loaded by the web app
- Metrics JSON files will populate the dashboard
- Inference code will be adapted for API endpoints

## ğŸ“š Additional Resources

- **PyTorch Documentation**: https://pytorch.org/docs/
- **Hugging Face**: https://huggingface.co/docs
- **TorchVision**: https://pytorch.org/vision/stable/
- **Detectron2**: https://detectron2.readthedocs.io/

## ğŸ¤ Contributing

To add a new notebook:
1. Follow the standard structure outlined above
2. Include automatic CUDA/CPU support
3. Add comprehensive documentation
4. Save metrics in JSON format
5. Update this README

## ğŸ“„ License

This ML portfolio is for educational and demonstration purposes.

---

**Status Legend:**
- âœ… Complete - Fully implemented with training pipeline
- ğŸ—ï¸ Template ready - Structure complete, awaiting detailed implementation
- ğŸ”„ In progress - Currently being developed

**Last Updated:** 2025-01-17
